---
title: 'Math 451 HW #19'
author: "Maxwell Levin"
date: "November 9, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1 (Textbook: 4.10)
#### The random pair $\small{(X, Y)}$ has the distribution:

\begin{table}[!h]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
$ $ & $X = 1$ & $X = 2$ & $X = 3$\\ \hline
$Y = 2$ & $1/12$ & $1/6$ & $1/12$\\ \hline
$Y = 3$ & $1/6$ & $0$ & $1/6$\\ \hline
$Y = 4$ & $0$ & $1/3$ & $0$\\ \hline
\end{tabular}
\end{table}

#### (a) Show that *X* and *Y* are dependent.

From our two way table we can construct the following marginal pmfs:
\[
f_X(x) = 
  \left\{
  \begin{array}{lllll}
     \frac{1}{4}, & \text{if }\text{ } x = 1; \\[1mm]
     \frac{1}{2}, & \text{if }\text{ } x = 2; \\[1mm]
     \frac{1}{4}, & \text{if }\text{ } x = 3; \\[1mm]
      0, & \text{otherwise.} \\[1mm]
  \end{array} 
  \right.
\]

\[
f_Y(y) = 
  \left\{
  \begin{array}{lllll}
     \frac{1}{3}, & \text{if }\text{ } y = 2; \\[1mm]
     \frac{1}{3}, & \text{if }\text{ } y = 3; \\[1mm]
     \frac{1}{3}, & \text{if }\text{ } y = 4; \\[1mm]
      0, & \text{otherwise.} \\[1mm]
  \end{array} 
  \right.
\]

For *X* and *Y* to be independent we require $\small{f_{X,Y}(x, y) = f_X(x)f_Y(y)}$, for all *x*, *y*. Consider the case where $\small{X = 1, Y = 4}$. We then have 
\[
  f_{X, Y}(x, y) = 0,
\]

and 
\[
  f_X(x)f_Y(y) = \frac{1}{4} \frac{1}{4} = \frac{1}{16} \neq 0.
\]

Thus *X* and *Y* must be dependent.

#### (b) Give a probability table for random variables *U* and *V* that have the same marginals as *X* and *Y* but are independent.

Consider the following table:

\begin{table}[!h]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
$ $ & $U = 1$ & $U = 2$ & $U = 3$\\ \hline
$V = 2$ & $1/12$ & $1/6$ & $1/12$\\ \hline
$V = 3$ & $1/12$ & $1/6$ & $1/12$\\ \hline
$V = 4$ & $1/12$ & $1/6$ & $1/12$\\ \hline
\end{tabular}
\end{table}

## Question 2 (Textbook: 4.14)
#### Suppose *X* and *Y* are independent random variables that are distributed by $\small{Normal(0, 1^2)}$.

#### (a) Find $\small{Pr\{X^2 + Y^2 < 1 \}}$.

Note that here we take the double integral:
\[
  \int \int \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2} \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}y^2} dxdy
\]

over $\small{\{X^2 + Y^2 < 1 \}}$ to get the $\small{Pr\{X^2 + Y^2 < 1 \}}$. To integrate this we make the following substitutions:
\[
  x = rcos(\theta),
\]
\[
  y = rsin(\theta).
\]

With these substitutions our integral becomes:
\[
  \int_0^{2\pi} \int_0^1 \frac{1}{2\pi}e^{-\frac{1}{2}r^2} r dr d\theta,
\]
\[
  = \int_0^1 r e^{-\frac{1}{2}r^2} dr,
\]
\[
  = - e^{-\frac{1}{2}r^2} \Big{|}_0^1,
\]
\[
  = 1 - \frac{1}{\sqrt{e}}.
\]

Thus we have found
\[
  Pr\{X^2 + Y^2 < 1 \} = 1 - \frac{1}{\sqrt{e}}.
\]

#### (b) Find $\small{Pr\{X^2 < 1 \}}$, after verifying that $\small{X^2}$ is distributed by $\small{\chi_1^2}$.

Note that we have shown in class that $\small{X^2}$ is distributed by $\small{\chi_1^2}$, so we do not repeat our work again here. To find $\small{Pr\{X^2 < 1 \}}$ we follow a similar process as in part (a) by taking the following integral:
\[
Pr\{X^2 < 1 \} = \int_{\{X^2 < 1\}} \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2}dx,
\]
\[
  = \int_0^1 \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2}dx.
\]

We can ask Wolfram Alpha (or whatever numerical integration program we wish to use) to compute this integral for us. Doing so we see that:
\[
  Pr\{X^2 < 1 \} \approx 0.341.
\]
